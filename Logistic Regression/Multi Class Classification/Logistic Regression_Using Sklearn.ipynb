{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required python modules\n",
    "import numpy as np \n",
    "from sklearn import linear_model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features=0\n",
    "classes=0\n",
    "samples=0\n",
    "\n",
    "def data_loader(filename,isTrainData):\n",
    "    # open data file\n",
    "    file = open(\"Data_files/\"+filename,\"r\")\n",
    "\n",
    "\n",
    "    # initialize\n",
    "    i=0\n",
    "    global features\n",
    "    global classes\n",
    "    global samples\n",
    "\n",
    "\n",
    "    listx = []\n",
    "    listy = []\n",
    "\n",
    "    for line in file:\n",
    "        # for the first line\n",
    "        if(i==0 and isTrainData==1):\n",
    "            fields = line.split()\n",
    "\n",
    "            features = int(fields[0])\n",
    "            classes = int(fields[1])\n",
    "            samples = int(fields[2])\n",
    "        # for the rest of the line\n",
    "        else:\n",
    "            fields = line.split()\n",
    "            templist = []\n",
    "\n",
    "            for j in range(features):\n",
    "                #print(fields[j])\n",
    "                templist.append(float(fields[j]))\n",
    "\n",
    "            listx.append(templist)\n",
    "            listy.append(int(fields[features]))\n",
    "\n",
    "        i = i+1\n",
    "\n",
    "    #print(str(features)+\" \"+str(classes)+\" \"+str(samples))\n",
    "\n",
    "    # convert into numpy array\n",
    "    x = np.array(listx)\n",
    "    y = np.array(listy)\n",
    "\n",
    "    #print(x.shape, y.shape)\n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(300, 3) (300,)\n(300, 3) (300,)\n"
    }
   ],
   "source": [
    "#load data from file\n",
    "#data = np.genfromtxt('iris.csv', delimiter=',',skip_header=True)\n",
    "\n",
    "#Distribute data into train and test sets\n",
    "#X_train = data[:80,[0,1,2,3]]\n",
    "X_train,Y_train = data_loader(\"MultiTrain.txt\",1)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "#X_test = data[-20:,[0,1,2,3]]\n",
    "X_test,Y_test = data_loader(\"MultiTest.txt\",0)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(max_iter=1000, solver='liblinear')"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#Generate the model\n",
    "model = linear_model.LogisticRegression(solver='liblinear',max_iter=1000)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Correct Count:  296  Total Wrong Count:  4  Accuracy:  98.66666666666667\n"
    }
   ],
   "source": [
    "#Calculate the performance of the model\n",
    "resultMatrix = model.predict(X_test)\n",
    "correctCount = sum((resultMatrix==Y_test).astype(int))\n",
    "totalCount = len(X_test)\n",
    "print(\"Total Correct Count: \",correctCount,\" Total Wrong Count: \",totalCount-correctCount,\" Accuracy: \",(correctCount*100)/(totalCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[-6.91871735 -0.24250899  1.35018949] [[ 0.02621413  0.89621243  0.16951097]\n [ 0.34454608 -1.49393842  0.32365124]\n [-1.62056209  1.59107513 -0.80355961]]\n"
    }
   ],
   "source": [
    "#Model Properties\n",
    "print(model.intercept_, model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[4.24129030e-04 1.12783554e-03 1.08631098e-03 7.35900627e-05\n 7.79185087e-04 2.79747645e-04 7.75772074e-04 1.15951887e-03\n 9.72849894e-05 8.44553179e-05 2.07016555e-04 3.23926686e-04\n 4.75388418e-04 5.09117132e-04 1.22336844e-04 3.25246159e-04\n 8.74733883e-04 1.11989541e-03 9.82063743e-05 3.61825799e-04\n 2.39854907e-03 9.21788452e-04 4.88583425e-04 3.06162823e-04\n 4.54295988e-05 7.27419616e-05 3.55286599e-04 2.51511332e-04\n 1.68962625e-04 1.63209201e-04 2.02088134e-04 4.28708851e-04\n 7.21863291e-04 1.10190986e-03 3.51095918e-04 5.98327675e-04\n 1.81327354e-03 3.29109486e-04 1.86707201e-03 3.74937698e-04\n 1.24856262e-04 3.39678845e-04 7.59361680e-04 8.46137843e-04\n 5.17963700e-04 4.85322882e-04 1.79778261e-03 1.59389443e-04\n 1.63501794e-04 3.97953793e-04 1.84168538e-04 2.76176012e-04\n 1.29052185e-04 1.21196403e-03 1.63746571e-03 1.94189601e-04\n 1.95300818e-04 2.41633525e-04 1.32154663e-04 4.61990106e-05\n 7.61842637e-04 1.06386760e-03 2.87497444e-05 1.17498652e-03\n 9.92438049e-03 4.13312599e-04 1.82234495e-03 3.92748569e-04\n 5.40932724e-04 4.11002052e-04 1.73104363e-04 1.81502543e-04\n 6.94845733e-04 1.38874085e-03 5.01305379e-05 3.47800359e-04\n 2.05203565e-03 2.26751615e-04 5.19848314e-04 4.59952572e-04\n 8.43037377e-05 9.83405718e-04 1.86834726e-04 2.53345352e-03\n 3.05427300e-04 3.98384320e-04 6.78730730e-03 8.74911005e-03\n 2.38894427e-04 1.04439925e-03 5.07358975e-04 1.38483109e-03\n 5.63200109e-04 1.37308219e-03 3.48792908e-05 1.82453208e-04\n 5.18583699e-03 6.00596756e-05 4.32581871e-04 2.05742554e-04\n 9.59309913e-01 9.89089830e-01 9.59927638e-01 9.71436742e-01\n 9.63691337e-01 9.55157566e-01 9.92118634e-01 9.90872466e-01\n 9.40652534e-01 8.21663655e-01 9.56846474e-01 9.84911310e-01\n 9.46621953e-01 9.51114595e-01 9.94023778e-01 9.62944418e-01\n 9.80853073e-01 9.26404270e-01 9.75609881e-01 9.97441843e-01\n 9.83479842e-01 9.91472828e-01 9.83229702e-01 9.89176254e-01\n 9.83623756e-01 9.83247862e-01 9.67252985e-01 9.82298217e-01\n 9.77362379e-01 9.91260360e-01 9.91959961e-01 9.77030643e-01\n 9.58917881e-01 9.45076850e-01 9.79506339e-01 9.44265548e-01\n 9.81713416e-01 9.52754618e-01 9.74340399e-01 9.82902914e-01\n 9.69328062e-01 9.68552172e-01 9.77618260e-01 9.94987342e-01\n 9.09912690e-01 9.86706291e-01 8.70916369e-01 9.51602003e-01\n 9.95618223e-01 9.78933535e-01 9.50861461e-01 9.59232186e-01\n 9.65147157e-01 9.77829904e-01 9.65071228e-01 9.73554854e-01\n 9.16381404e-01 9.59958729e-01 9.76232141e-01 9.77572499e-01\n 9.71560662e-01 9.80958058e-01 9.90410636e-01 9.77682207e-01\n 9.48120064e-01 9.64677277e-01 9.38279712e-01 9.46779684e-01\n 9.88237150e-01 9.35721422e-01 9.85573011e-01 9.81720853e-01\n 9.91880484e-01 9.41541124e-01 9.67935545e-01 9.77006800e-01\n 9.71764680e-01 9.64767841e-01 9.77871144e-01 9.88341018e-01\n 9.85769094e-01 9.38026789e-01 9.58811816e-01 9.79088032e-01\n 9.65398841e-01 9.86150242e-01 8.96661528e-01 9.47470538e-01\n 9.54148137e-01 9.54716440e-01 9.29528462e-01 8.89462327e-01\n 9.29158381e-01 9.88891449e-01 9.85433545e-01 9.45829115e-01\n 9.51195077e-01 9.60125337e-01 9.70511298e-01 9.73969871e-01\n 1.53942932e-03 2.34272573e-03 8.17283401e-04 8.47759958e-03\n 2.85919400e-03 1.27415943e-03 3.48583632e-04 6.36081208e-04\n 5.24361475e-04 7.54930285e-05 1.70455757e-04 2.57905803e-03\n 4.29339044e-04 7.52882942e-04 1.13198963e-04 7.21887699e-04\n 1.10741093e-03 5.64188871e-04 8.54639145e-05 1.03003901e-03\n 2.79168693e-02 9.62411031e-03 4.04674127e-03 6.88954175e-03\n 1.42639653e-03 2.32408915e-03 2.41823570e-03 8.34768972e-03\n 2.51490914e-03 4.82902690e-04 1.66691419e-03 8.87926093e-03\n 1.23838292e-03 1.37312308e-03 1.06095180e-03 6.99478771e-04\n 7.78540387e-02 4.21684419e-04 1.25578417e-03 1.77891520e-03\n 4.59763953e-04 6.24373346e-04 4.27861548e-04 5.90479235e-03\n 2.05176126e-03 2.69941384e-03 4.38456178e-03 7.32332253e-04\n 3.23863228e-04 4.07199022e-04 3.51654071e-04 7.82542170e-04\n 3.82070267e-03 1.53136850e-03 5.02060027e-04 1.10806752e-03\n 1.14696413e-03 2.95086577e-03 7.64740824e-03 9.13977185e-04\n 3.87922419e-04 7.93416236e-04 6.44579310e-04 1.09661033e-03\n 4.89366935e-04 2.08101279e-04 3.74104346e-03 3.52878184e-03\n 3.48374053e-03 2.18758824e-04 4.91327799e-04 1.96481843e-03\n 5.08753530e-04 6.81442185e-03 1.01012878e-03 1.04387276e-04\n 1.39271799e-03 9.63668639e-04 4.11479504e-04 1.70718491e-03\n 4.84069260e-03 1.26916294e-02 1.77671049e-03 2.87113365e-03\n 5.92616283e-03 3.81525092e-04 2.15126634e-03 8.87988733e-04\n 7.72080020e-04 9.10170317e-04 7.58960269e-04 1.68605312e-04\n 5.85875981e-03 2.20381580e-03 1.75811712e-03 1.12431579e-02\n 1.89625491e-03 3.48521575e-04 9.22527615e-05 2.33060234e-04]\n"
    }
   ],
   "source": [
    "#Predicted values for the test set\n",
    "print(model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}