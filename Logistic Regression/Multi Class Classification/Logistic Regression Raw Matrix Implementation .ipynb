{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required python modules\n",
    "import numpy as np \n",
    "from sklearn import linear_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features=0\n",
    "classes=0\n",
    "samples=0\n",
    "\n",
    "def data_loader(filename,isTrainData):\n",
    "    # open data file\n",
    "    file = open(\"Data_files/\"+filename,\"r\")\n",
    "\n",
    "\n",
    "    # initialize\n",
    "    i=0\n",
    "    global features\n",
    "    global classes\n",
    "    global samples\n",
    "\n",
    "\n",
    "    listx = []\n",
    "    listy = []\n",
    "\n",
    "    for line in file:\n",
    "        # for the first line\n",
    "        if(i==0 and isTrainData==1):\n",
    "            fields = line.split()\n",
    "\n",
    "            features = int(fields[0])\n",
    "            classes = int(fields[1])\n",
    "            samples = int(fields[2])\n",
    "        # for the rest of the line\n",
    "        else:\n",
    "            fields = line.split()\n",
    "            templist = []\n",
    "\n",
    "            for j in range(features):\n",
    "                #print(fields[j])\n",
    "                templist.append(float(fields[j]))\n",
    "\n",
    "            listx.append(templist)\n",
    "            listy.append(int(fields[features]))\n",
    "\n",
    "        i = i+1\n",
    "\n",
    "    #print(str(features)+\" \"+str(classes)+\" \"+str(samples))\n",
    "\n",
    "    # convert into numpy array\n",
    "    x = np.array(listx)\n",
    "    y = np.array(listy)\n",
    "\n",
    "    #print(x.shape, y.shape)\n",
    "    \n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(300, 3) (300,)\n(300, 3) (300,)\n"
    }
   ],
   "source": [
    "#load data from file\n",
    "#data = np.genfromtxt('iris.csv', delimiter=',',skip_header=True)\n",
    "\n",
    "#Distribute data into train and test sets\n",
    "#X_train = data[:80,[0,1,2,3]]\n",
    "X_train,Y_train = data_loader(\"MultiTrain.txt\",1)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "#X_test = data[-20:,[0,1,2,3]]\n",
    "X_test,Y_test = data_loader(\"MultiTest.txt\",0)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the required Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n-207.944154167984\n[[-0.025     ]\n [-0.19354725]\n [ 0.07345308]\n [-0.14645753]]\n100\n-138.41909617388782\n[[-2.12554   ]\n [-0.38388263]\n [ 0.53815812]\n [ 0.24491806]]\n200\n-74.89371896375144\n[[-3.70762295]\n [-0.26599168]\n [ 0.69000455]\n [ 0.36081645]]\n300\n-47.573931737761974\n[[-4.78234731]\n [-0.17563918]\n [ 0.69263092]\n [ 0.32680168]]\n400\n-38.93517679044773\n[[-5.48780631]\n [-0.10505161]\n [ 0.74852121]\n [ 0.25793161]]\n500\n-33.72104040231796\n[[-5.9868761 ]\n [-0.04711232]\n [ 0.80087659]\n [ 0.21980101]]\n600\n-29.969207023274596\n[[-6.41549396]\n [-0.01720141]\n [ 0.84544119]\n [ 0.20179329]]\n700\n-27.029528704418343\n[[-6.79562189e+00]\n [ 2.52590207e-03]\n [ 8.85720896e-01]\n [ 1.93944962e-01]]\n800\n-24.659536626421893\n[[-7.13715601]\n [ 0.01740059]\n [ 0.92229554]\n [ 0.19051503]]\n900\n-22.706571710247115\n[[-7.44728523]\n [ 0.02957003]\n [ 0.95568152]\n [ 0.18910227]]\n0\n-207.944154167984\n[[-0.025     ]\n [ 0.10028855]\n [-0.32175738]\n [ 0.10352738]]\n100\n-0.8195550561941949\n[[-0.10293206]\n [ 0.29062987]\n [-1.35449296]\n [ 0.31151287]]\n200\n-0.5384222679981493\n[[-0.12082556]\n [ 0.31527789]\n [-1.46523062]\n [ 0.33489137]]\n300\n-0.4045452438734964\n[[-0.13374779]\n [ 0.33241813]\n [-1.54202539]\n [ 0.350869  ]]\n400\n-0.32563751515645917\n[[-0.14397066]\n [ 0.34563   ]\n [-1.60108261]\n [ 0.36303494]]\n500\n-0.27337549513582826\n[[-0.15247889]\n [ 0.35640742]\n [-1.64917964]\n [ 0.37286745]]\n600\n-0.23610092539243777\n[[-0.15979374]\n [ 0.36552306]\n [-1.68981205]\n [ 0.3811226 ]]\n700\n-0.20811567644812784\n[[-0.16622642]\n [ 0.37342981]\n [-1.72502408]\n [ 0.38823955]]\n800\n-0.1862971316959848\n[[-0.17197845]\n [ 0.38041643]\n [-1.7561167 ]\n [ 0.39449616]]\n900\n-0.16878752891393414\n[[-0.17718816]\n [ 0.3866786 ]\n [-1.78397002]\n [ 0.40007944]]\n0\n-207.944154167984\n[[-0.025     ]\n [-0.602869  ]\n [-0.12694417]\n [-0.45869877]]\n100\n-9.17807108664216\n[[ 0.42194603]\n [-0.96481727]\n [ 1.12754043]\n [-0.76695238]]\n200\n-6.061644048198225\n[[ 0.58092965]\n [-1.19780382]\n [ 1.37190042]\n [-0.8732131 ]]\n300\n-4.741811636167802\n[[ 0.69660809]\n [-1.35582235]\n [ 1.52625126]\n [-0.92728519]]\n400\n-3.9737079067603656\n[[ 0.79078018]\n [-1.47833264]\n [ 1.64061587]\n [-0.96122535]]\n500\n-3.4580269581538636\n[[ 0.87153377]\n [-1.57934947]\n [ 1.73201631]\n [-0.98509536]]\n600\n-3.082338183644659\n[[ 0.9429102 ]\n [-1.6656888 ]\n [ 1.80840113]\n [-1.00319978]]\n700\n-2.7937149747412895\n[[ 1.00727012]\n [-1.74125802]\n [ 1.87415529]\n [-1.01770463]]\n800\n-2.56353020496756\n[[ 1.06613355]\n [-1.80853759]\n [ 1.93196559]\n [-1.02981809]]\n900\n-2.3747654732595347\n[[ 1.12054676]\n [-1.86921519]\n [ 1.98360254]\n [-1.04026471]]\n"
    }
   ],
   "source": [
    "#Define the Raw implementation function to set the parameters (theta)\n",
    "\n",
    "def fit_implementation(X_train, Y_train, Class,learning_rate=0.0005, max_iteration=1000):\n",
    "    #Adding a column of 1's so that the first element of each input is always 1\n",
    "    #It would be multiplied with theta_0 later\n",
    "    X_train= np.insert(X_train, 0, values=1, axis=1)\n",
    "    no_attributes = X_train.shape[1]\n",
    "    \n",
    "    #Initialize model parameters theta\n",
    "    theta = np.zeros((no_attributes,1))\n",
    "    \n",
    "    #Run number of iterations\n",
    "    for icount in range(max_iteration):\n",
    "        #delta is the quantity that will be added with theta during updating theta\n",
    "        delta = np.zeros((no_attributes,1))\n",
    "        totalLogLikelihood = 0\n",
    "        #Check each data point\n",
    "        for instance, actualOutput in zip(X_train,Y_train):\n",
    "            if actualOutput == Class:\n",
    "                actualOutput = 1\n",
    "            else:\n",
    "                actualOutput = 0\n",
    "            instance=instance.reshape(no_attributes,1)\n",
    "            dotResult = np.dot(theta.T, instance)\n",
    "            \n",
    "            predictedOutput=sigmoid(dotResult).squeeze()\n",
    "            #Calculate the derivative value for this data point\n",
    "            derivativeValue = instance*(actualOutput-predictedOutput)\n",
    "            #Calculate the amount to be added with theta\n",
    "            delta += learning_rate*derivativeValue\n",
    "\n",
    "            logLikelihood = actualOutput*np.log(predictedOutput)+(1-actualOutput)*np.log(1-predictedOutput)\n",
    "            totalLogLikelihood += logLikelihood\n",
    "        theta = theta + delta\n",
    "        \n",
    "        #After each 100 iteration, print the status\n",
    "        if icount%100==0:\n",
    "            print(icount)\n",
    "            print(totalLogLikelihood)\n",
    "            print(theta)\n",
    "    #print(theta.shape)\n",
    "    \n",
    "    return theta\n",
    "\n",
    "def fit_implementation2(X_train, Y_train,Class, learning_rate=0.0005, max_iteration=1000):\n",
    "    #Adding a column of 1's so that the first element of each input is always 1\n",
    "    #It would be multiplied with theta_0 later\n",
    "    X_train= np.insert(X_train, 0, values=1, axis=1)\n",
    "    no_attributes = X_train.shape[1]\n",
    "    Y_train = Y_train.reshape(-1,1)\n",
    "    Y_train = np.where( Y_train ==Class,1,0)\n",
    "    \n",
    "    #Initialize model parameters theta\n",
    "    theta = np.zeros((no_attributes,1))\n",
    "    \n",
    "    #Run number of iterations\n",
    "    for icount in range(max_iteration):\n",
    "        #delta is the quantity that will be added with theta during updating theta\n",
    "        delta = np.zeros((no_attributes,1))\n",
    "        totalLogLikelihood = 0\n",
    "        \n",
    "        dotResult = np.dot(X_train,theta)\n",
    "        #print(\"Dot Result: \",dotResult.shape)\n",
    "        predictedValue = sigmoid(dotResult)\n",
    "        #print(\"predictedValue: \",predictedValue.shape)\n",
    "        diff = Y_train - predictedValue\n",
    "        #print(\"diff: \",diff.shape)\n",
    "        derivativeValue = X_train*diff\n",
    "        #print(\"derivativeValue: \",derivativeValue.shape)\n",
    "        delta = learning_rate*derivativeValue\n",
    "        #print(\"delta: \",delta.shape)\n",
    "        delta = np.sum(delta, axis=0).reshape(no_attributes,-1)\n",
    "        #print(\"delta Updated: \",delta.shape)\n",
    "        logLikelihood = Y_train*np.log(predictedValue) + (1-Y_train)*np.log(1-predictedValue)\n",
    "        #print(\"logLikelihood: \",logLikelihood.shape)\n",
    "        totalLogLikelihood = np.sum(logLikelihood)\n",
    "        theta = theta + delta\n",
    "        \n",
    "        #After each 100 iteration, print the status\n",
    "        if icount%100==0:\n",
    "            print(icount)\n",
    "            print(totalLogLikelihood)\n",
    "            print(theta)\n",
    "    #print(theta.shape)\n",
    "    \n",
    "    return theta\n",
    "\n",
    "\n",
    "#parameters = fit_implementation(X_train, Y_train)\n",
    "parameters = []\n",
    "for i in range(classes):\n",
    "    parameters.append(fit_implementation(X_train, Y_train,i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 2\n2 1\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 2\n2 3\n3 2\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\n3 3\nTotal Correct Count:  296  Total Wrong Count:  4  Accuracy:  98.66666666666667\n"
    }
   ],
   "source": [
    "def prediction(X_test, Y_test, thetas):\n",
    "    #Adding a column of 1's so that the first element of each input is always 1\n",
    "    #It would be multiplied with theta_0 later\n",
    "    X_test= np.insert(X_test, 0, values=1, axis=1)\n",
    "    no_attributes = X_test.shape[1]\n",
    "    \n",
    "    correctCount = 0\n",
    "    totalCount = 0\n",
    "    \n",
    "    #Check each data point\n",
    "    for instance, actualOutput in zip(X_test,Y_test):\n",
    "            instance=instance.reshape(no_attributes,1)\n",
    "            predictedValue = []\n",
    "            predictedOutput = -1\n",
    "            for theta in thetas:\n",
    "                dotResult = np.dot(theta.T, instance)\n",
    "                predictedValue.append(sigmoid(dotResult).squeeze())\n",
    "\n",
    "            predictedOutput = predictedValue.index(max(predictedValue)) +1\n",
    "            \n",
    "            print(predictedOutput, actualOutput)\n",
    "            if predictedOutput == actualOutput:\n",
    "                correctCount += 1\n",
    "            totalCount += 1\n",
    "    print(\"Total Correct Count: \",correctCount,\" Total Wrong Count: \",totalCount-correctCount,\" Accuracy: \",(correctCount*100)/(totalCount))\n",
    "    \n",
    "prediction(X_test, Y_test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}